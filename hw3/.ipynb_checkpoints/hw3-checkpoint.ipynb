{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание по проекту. \n",
    "\n",
    "Для его выполнения вам понадобится собранная коллекция документов и функция, составляющая обратный индекс по словам в коллекции.\n",
    "\n",
    "Напишите функцию (или несколько отдельных логичный функций), которая по запросу  Q=q1,...,gnQ=q1,...,gn  и коллекции  DD  сортирует выдачу подходящих документов. Будем считать документ подходящим, если он содержит хотя бы одно слово из запроса (из которого удалены стоп-слова). В качестве метрики используйте Okapi BM25.\n",
    "Для проверки работы функции на вашем корпусе используйте запрос каникулы на новый год и рождество. Выведите ссылки в ipynb на первые десять докуменов в отсортированной выдаче(как во втором семинаре с помощью IPython.display) и их оценку BM25. Напомню, что ссылки на документы хрянятся в самих доках под тэгом @url."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом случае можно использовать формулу *Okapi best match 25* ([Okapi BM25](https://ru.wikipedia.org/wiki/Okapi_BM25)). Пусть дан запрос $Q$, содержащий слова  $q_1, ... , q_n$, тогда функция BM25 даёт следующую оценку релевантности документа $D$ запросу $Q$:\n",
    "\n",
    "$$ score(D, Q) = \\sum_{i}^{n} \\text{IDF}(q_i)*\\frac{(k+1)*f(q_i,D)}{f(q_i,D)+k_1(1-b+b\\frac{|D|}{avgdl})} $$ \n",
    "где $f(q_i,D)$ - частота слова (TF) $q_i$ в документе $D$, $|D|$ - длина документа (количество слов в нём), а *avgdl* — средняя длина документа в коллекции. \n",
    "$$$$\n",
    "$k_1$ и $b$ — свободные коэффициенты, обычно их выбирают как $k_1$=2.0 и $b$=0.75.\n",
    "$$$$\n",
    "$\\text{IDF}(q_i)$ есть обратная документная частота (IDF) слова $q_i$: \n",
    "$$\\text{IDF}(q_i) = \\log\\frac{N-n(q_i)+0.5}{n(q_i)+0.5},$$\n",
    "где $N$ - общее количество документов в коллекции, а  $n(q_i)$ — количество документов, содержащих $q_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.sparse import dok_matrix\n",
    "#import numpy as np\n",
    "#from collections import defaultdict\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from math import log\n",
    "from collections import Counter,  defaultdict\n",
    "import glob\n",
    "#from pymystem3 import Mystem\n",
    "from pymystem3 import Mystem\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = 2.0\n",
    "b = 0.75\n",
    "\n",
    "'''qf - word frequency in the doc\n",
    "dl - doc length(number of words in the doc)\n",
    "avdl - medium length of doc in the collection\n",
    "N - number of documents in the collection\n",
    "n - number of docs with a certain word (number of indexes)'''\n",
    "\n",
    "def score_BM25(n, qf, N, dl, avdl):\n",
    "    K = compute_K(dl, avdl)\n",
    "    IDF = log((N - n + 0.5) / (n + 0.5))\n",
    "    frac = ((k1 + 1) * fq) / (K + fq)\n",
    "    return IDF * frac\n",
    "\n",
    "def compute_K(dl, avdl):\n",
    "    return k1 * ((1-b) + b * (float(dl)/float(avdl)))\n",
    "\n",
    "\n",
    "def BM25_foralldocs(query, list_of_word_massives, frequency, index_dict, BM25_for_all):\n",
    "    \n",
    "    avdl = 0\n",
    "    \n",
    "    for doc in list_of_word_massives:\n",
    "        total_dl += len(doc)\n",
    "        \n",
    "    for n_text, doc in enumerate(list_of_word_massives):\n",
    "        for word in query:\n",
    "            score = score_BM25(index_dict[word], frequency[str(n_text)][word], len(list_of_word_massives),\n",
    "                               len(list_of_word_massives[str(n_text)]), (total_dl/len(list_of_word_massives)))\n",
    "            if str(n_text) in BM25_for_all:\n",
    "                BM25_for_all[str(n_text)] += score\n",
    "            else:\n",
    "                BM25_for_all[str(n_text)] = score\n",
    "        \n",
    "    return BM25_for_all\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: с новым годом клубе\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'приобретение'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-f429a3f445f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     78\u001b[0m print(BM25_foralldocs(query, text_to_words_massive(list_of_docs, stop_words_list), \n\u001b[0;32m     79\u001b[0m                       \u001b[0mword_frequency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_to_words_massive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_docs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrequency_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                       reverse_index(text_to_words_massive(list_of_docs, stop_words_list), index_dict), BM25_for_all))                                                                          \n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-f429a3f445f1>\u001b[0m in \u001b[0;36mreverse_index\u001b[1;34m(list_of_word_massives, index_dict)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_word_massives\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_text\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindex_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m                 \u001b[0mindex_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mindex_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'приобретение'"
     ]
    }
   ],
   "source": [
    "#functions copied from hw1(a bit modified)\n",
    "def text_to_words_massive(list_of_docs, stop_words):                                                               \n",
    "    list_of_word_massives = []\n",
    "    for doc in list_of_docs:\n",
    "        m = Mystem()\n",
    "        all_words = m.lemmatize(open(doc, 'r', encoding='UTF-8').read())\n",
    "        \n",
    "        all_words_clean = []\n",
    "        for w in all_words: \n",
    "            if w in stop_words or re.search('[А-Яа-я]', w) == None:\n",
    "                pass\n",
    "            else:\n",
    "                all_words_clean.append(w)\n",
    "        \n",
    "        '''all_words_clean = []\n",
    "        for w in all_words: \n",
    "            \n",
    "            if word not in stop_words:\n",
    "                all_words_clean.append(w)\n",
    "            else:\n",
    "                pass'''\n",
    "        list_of_word_massives.append(all_words_clean)\n",
    "        \n",
    "    return list_of_word_massives\n",
    "    \n",
    "\n",
    "def reverse_index(list_of_word_massives, index_dict):\n",
    "    #функция выдающая массив индексов для каждого слова в коллекции документов\n",
    "    for n_text, doc in enumerate(list_of_word_massives):\n",
    "        for word in set(doc):\n",
    "            index_dict.setdefault(word, [])\n",
    "            if str(n_text) not in index_dict[word]:\n",
    "                index_dict[word].append(str(n_text))\n",
    "\n",
    "    return index_dict\n",
    "\n",
    "\n",
    "def word_frequency(list_of_word_massives, frequency):            \n",
    "    #функция, подсчитывающая частоту каждого слова для каждого документа в коллекции\n",
    "    for n, doc in enumerate(list_of_word_massives):\n",
    "        frequency_dict = {}\n",
    "        for word in doc:\n",
    "            if word in frequency_dict:\n",
    "                frequency_dict[word] += 1\n",
    "            else:\n",
    "                frequency_dict[word] = 1\n",
    "        \n",
    "        for word in frequency_dict:\n",
    "            frequency_dict[word] = frequency_dict[word]/len(doc)\n",
    "        \n",
    "        frequency[str(n)] = frequency_dict\n",
    "            \n",
    "    return frequency\n",
    "\n",
    "\n",
    "stop_words_list = [\"а\",\"алло\",\"без\",\"белый\",\"близко\",\"более\",\"больше\",\"большой\",\"будем\",\"будет\",\"будете\",\"будешь\",\"будто\",\"буду\",\"будут\",\"будь\",\"бы\",\"бывает\",\"бывь\",\"был\",\"была\",\"были\",\"было\",\"быть\",\"в\",\"важная\",\"важное\",\"важные\",\"важный\",\"вам\",\"вами\",\"вас\",\"ваш\",\"ваша\",\"ваше\",\"ваши\",\"вверх\",\"вдали\",\"вдруг\",\"ведь\",\"везде\",\"вернуться\",\"весь\",\"вечер\",\"взгляд\",\"взять\",\"вид\",\"видеть\",\"вместе\",\"вниз\",\"внизу\",\"во\",\"вода\",\"война\",\"вокруг\",\"вон\",\"вообще\",\"вопрос\",\"восемнадцатый\",\"восемнадцать\",\"восемь\",\"восьмой\",\"вот\",\"впрочем\",\"времени\",\"время\",\"все\",\"всегда\",\"всего\",\"всем\",\"всеми\",\"всему\",\"всех\",\"всею\",\"всю\",\"всюду\",\"вся\",\"всё\",\"второй\",\"вы\",\"выйти\",\"г\",\"где\",\"главный\",\"глаз\",\"говорил\",\"говорит\",\"говорить\",\"год\",\"года\",\"году\",\"голова\",\"голос\",\"город\",\"да\",\"давать\",\"давно\",\"даже\",\"далекий\",\"далеко\",\"дальше\",\"даром\",\"дать\",\"два\",\"двадцатый\",\"двадцать\",\"две\",\"двенадцатый\",\"двенадцать\",\"дверь\",\"двух\",\"девятнадцатый\",\"девятнадцать\",\"девятый\",\"девять\",\"действительно\",\"дел\",\"делать\",\"дело\",\"день\",\"деньги\",\"десятый\",\"десять\",\"для\",\"до\",\"довольно\",\"долго\",\"должно\",\"должный\",\"дом\",\"дорога\",\"друг\",\"другая\",\"другие\",\"других\",\"друго\",\"другое\",\"другой\",\"думать\",\"душа\",\"е\",\"его\",\"ее\",\"ей\",\"ему\",\"если\",\"есть\",\"еще\",\"ещё\",\"ею\",\"её\",\"ж\",\"ждать\",\"же\",\"жена\",\"женщина\",\"жизнь\",\"жить\",\"за\",\"занят\",\"занята\",\"занято\",\"заняты\",\"затем\",\"зато\",\"зачем\",\"здесь\",\"земля\",\"знать\",\"значит\",\"значить\",\"и\",\"идти\",\"из\",\"или\",\"им\",\"именно\",\"иметь\",\"ими\",\"имя\",\"иногда\",\"их\",\"к\",\"каждая\",\"каждое\",\"каждые\",\"каждый\",\"кажется\",\"казаться\",\"как\",\"какая\",\"какой\",\"кем\",\"книга\",\"когда\",\"кого\",\"ком\",\"комната\",\"кому\",\"конец\",\"конечно\",\"которая\",\"которого\",\"которой\",\"которые\",\"который\",\"которых\",\"кроме\",\"кругом\",\"кто\",\"куда\",\"лежать\",\"лет\",\"ли\",\"лицо\",\"лишь\",\"лучше\",\"любить\",\"люди\",\"м\",\"маленький\",\"мало\",\"мать\",\"машина\",\"между\",\"меля\",\"менее\",\"меньше\",\"меня\",\"место\",\"миллионов\",\"мимо\",\"минута\",\"мир\",\"мира\",\"мне\",\"много\",\"многочисленная\",\"многочисленное\",\"многочисленные\",\"многочисленный\",\"мной\",\"мною\",\"мог\",\"могут\",\"мож\",\"может\",\"можно\",\"можхо\",\"мои\",\"мой\",\"мор\",\"москва\",\"мочь\",\"моя\",\"моё\",\"мы\",\"на\",\"наверху\",\"над\",\"надо\",\"назад\",\"наиболее\",\"найти\",\"наконец\",\"нам\",\"нами\",\"народ\",\"нас\",\"начала\",\"начать\",\"наш\",\"наша\",\"наше\",\"наши\",\"не\",\"него\",\"недавно\",\"недалеко\",\"нее\",\"ней\",\"некоторый\",\"нельзя\",\"нем\",\"немного\",\"нему\",\"непрерывно\",\"нередко\",\"несколько\",\"нет\",\"нею\",\"неё\",\"ни\",\"нибудь\",\"ниже\",\"низко\",\"никакой\",\"никогда\",\"никто\",\"никуда\",\"ними\",\"них\",\"ничего\",\"ничто\",\"но\",\"новый\",\"нога\",\"ночь\",\"ну\",\"нужно\",\"нужный\",\"нх\",\"о\",\"об\",\"оба\",\"обычно\",\"один\",\"одиннадцатый\",\"одиннадцать\",\"однажды\",\"однако\",\"одного\",\"одной\",\"оказаться\",\"окно\",\"около\",\"он\",\"она\",\"они\",\"оно\",\"опять\",\"особенно\",\"остаться\",\"от\",\"ответить\",\"отец\",\"отовсюду\",\"отсюда\",\"очень\",\"первый\",\"перед\",\"писать\",\"плечо\",\"по\",\"под\",\"подумать\",\"пожалуйста\",\"позже\",\"пойти\",\"пока\",\"пол\",\"получить\",\"помнить\",\"понимать\",\"понять\",\"пор\",\"пора\",\"после\",\"последний\",\"посмотреть\",\"посреди\",\"потом\",\"потому\",\"почему\",\"почти\",\"правда\",\"прекрасно\",\"при\",\"про\",\"просто\",\"против\",\"процентов\",\"пятнадцатый\",\"пятнадцать\",\"пятый\",\"пять\",\"работа\",\"работать\",\"раз\",\"разве\",\"рано\",\"раньше\",\"ребенок\",\"решить\",\"россия\",\"рука\",\"русский\",\"ряд\",\"рядом\",\"с\",\"сам\",\"сама\",\"сами\",\"самим\",\"самими\",\"самих\",\"само\",\"самого\",\"самой\",\"самом\",\"самому\",\"саму\",\"самый\",\"свет\",\"свое\",\"своего\",\"своей\",\"свои\",\"своих\",\"свой\",\"свою\",\"сделать\",\"сеаой\",\"себе\",\"себя\",\"сегодня\",\"седьмой\",\"сейчас\",\"семнадцатый\",\"семнадцать\",\"семь\",\"сидеть\",\"сила\",\"сих\",\"сказал\",\"сказала\",\"сказать\",\"сколько\",\"слишком\",\"слово\",\"случай\",\"смотреть\",\"сначала\",\"снова\",\"со\",\"собой\",\"собою\",\"советский\",\"совсем\",\"спасибо\",\"спросить\",\"сразу\",\"стал\",\"старый\",\"стать\",\"стол\",\"сторона\",\"стоять\",\"страна\",\"суть\",\"считать\",\"т\",\"та\",\"так\",\"такая\",\"также\",\"таки\",\"такие\",\"такое\",\"такой\",\"там\",\"твой\",\"твоя\",\"твоё\",\"те\",\"тебе\",\"тебя\",\"тем\",\"теми\",\"теперь\",\"тех\",\"то\",\"тобой\",\"тобою\",\"товарищ\",\"тогда\",\"того\",\"тоже\",\"только\",\"том\",\"тому\",\"тот\",\"тою\",\"третий\",\"три\",\"тринадцатый\",\"тринадцать\",\"ту\",\"туда\",\"тут\",\"ты\",\"тысяч\",\"у\",\"увидеть\",\"уж\",\"уже\",\"улица\",\"уметь\",\"утро\",\"хороший\",\"хорошо\",\"хотеть\",\"хоть\",\"хотя\",\"хочешь\",\"час\",\"часто\",\"часть\",\"чаще\",\"чего\",\"человек\",\"чем\",\"чему\",\"через\",\"четвертый\",\"четыре\",\"четырнадцатый\",\"четырнадцать\",\"что\",\"чтоб\",\"чтобы\",\"чуть\",\"шестнадцатый\",\"шестнадцать\",\"шестой\",\"шесть\",\"эта\",\"эти\",\"этим\",\"этими\",\"этих\",\"это\",\"этого\",\"этой\",\"этом\",\"этому\",\"этот\",\"эту\",\"я\"]\n",
    "\n",
    "index_dict = {}\n",
    "frequency_dict = {}\n",
    "whole_list_of_docs = []\n",
    "total_w_in_doc = {}\n",
    "BM25_for_all = {}\n",
    "m = Mystem()\n",
    "q = input(\"search: \")\n",
    "query = m.lemmatize(q)\n",
    "#for n in range (len(query)):\n",
    "    #m = Mystem()\n",
    "    #query[n] = m.lemmatize(query[n].strip('!:\"?,;.-\\)\\('))\n",
    "\n",
    "for filename in glob.iglob('./articles/*.txt'):\n",
    "    whole_list_of_docs.append(filename)\n",
    "#print(whole_list_of_docs)\n",
    "list_of_docs = []    \n",
    "for i in range(5):\n",
    "    list_of_docs.append(whole_list_of_docs[i])\n",
    "#print(list_of_docs)\n",
    "    \n",
    "print(BM25_foralldocs(query, text_to_words_massive(list_of_docs, stop_words_list), \n",
    "                      word_frequency(text_to_words_massive(list_of_docs, stop_words_list), frequency_dict),\n",
    "                      reverse_index(text_to_words_massive(list_of_docs, stop_words_list), index_dict), BM25_for_all))                                                                          \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
